{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5254bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".+++++++++++++++++++++\n",
    ".............................................................................................................................................................\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82dd9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ANKUSH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21444416",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r\"C:\\Users\\ANKUSH\\Downloads\\NLP-with-Disaster-Tweets-main\\NLP-with-Disaster-Tweets-main\\train.csv\")\n",
    "Train.drop(['id', 'keyword', 'location'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12ae8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target\n",
      "0     Our Deeds are the Reason of this #earthquake M...       1\n",
      "1                Forest fire near La Ronge Sask. Canada       1\n",
      "2     All residents asked to 'shelter in place' are ...       1\n",
      "3     13,000 people receive #wildfires evacuation or...       1\n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
      "...                                                 ...     ...\n",
      "7608  Two giant cranes holding a bridge collapse int...       1\n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
      "7611  Police investigating after an e-bike collided ...       1\n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
      "\n",
      "[7613 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cef2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['text'] = Train['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33f9ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANKUSH\\AppData\\Local\\Temp\\ipykernel_14404\\2749212976.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Train['text'][i] = re.sub(r'http\\S+', '', Train['text'][i])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Train)):\n",
    "    Train['text'][i] = re.sub(r'http\\S+', '', Train['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6fe10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Punc = list('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''')\n",
    "for p in Punc:\n",
    "    Train['text'] = Train['text'].str.replace(p, '',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7bc7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tknzr = TweetTokenizer()\n",
    "Train['text'] = Train['text'].apply(lambda x: Tknzr.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa49bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lem = WordNetLemmatizer()\n",
    "Train['text'] = Train['text'].apply(lambda tokens: [Lem.lemmatize(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "decbe8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ANKUSH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "084b669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANKUSH\\AppData\\Local\\Temp\\ipykernel_14404\\3266534853.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Train['text'][i] = \" \".join([x for x in Train['text'][i] if x not in st])\n"
     ]
    }
   ],
   "source": [
    "st = stopwords.words('english')\n",
    "for i in range(len(Train)):\n",
    "    Train['text'][i] = \" \".join([x for x in Train['text'][i] if x not in st])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81c281a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv = TfidfVectorizer(max_features=5000)\n",
    "X = Cv.fit_transform(Train['text'])\n",
    "Y = Train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03d56a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49aafb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1059046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Na√Øve Bayes classifier\n",
    "Clf1 = MultinomialNB()\n",
    "Clf1.fit(X_train, Y_train)\n",
    "Pred = Clf1.predict(X_test)\n",
    "Score_nb = metrics.accuracy_score(Y_test, Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97395c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Random Forest classifier\n",
    "Clf2 = RandomForestClassifier(n_estimators=150)\n",
    "Clf2.fit(X_train, Y_train)\n",
    "Pred = Clf2.predict(X_test)\n",
    "Score_rf = metrics.accuracy_score(Y_test, Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6d6528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Decision Tree classifier\n",
    "Clf3 = DecisionTreeClassifier(max_depth=100)\n",
    "Clf3.fit(X_train, Y_train)\n",
    "Pred = Clf3.predict(X_test)\n",
    "Score_dt = metrics.accuracy_score(Y_test, Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23845313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Naive Bayes): 0.7974532431356944\n",
      "Accuracy Score (Random Forest): 0.7958615200955034\n",
      "Accuracy Score (Decision Tree): 0.759649820931158\n",
      "Accuracy Score (Logistic Regression): 0.8058097890966972\n",
      "Recall Score (Logistic Regression): 0.6803827751196172\n",
      "F1 Score (Logistic Regression): 0.7445026178010471\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a Logistic Regression classifier\n",
    "Clf4 = LogisticRegression(random_state=0)\n",
    "Clf4.fit(X_train, Y_train)\n",
    "Pred = Clf4.predict(X_test)\n",
    "Accuracy = metrics.accuracy_score(Y_test, Pred)\n",
    "Recall = metrics.recall_score(Y_test, Pred)\n",
    "F1 = metrics.f1_score(Y_test, Pred)\n",
    "print(\"Accuracy Score (Naive Bayes):\", Score_nb)\n",
    "print(\"Accuracy Score (Random Forest):\", Score_rf)\n",
    "print(\"Accuracy Score (Decision Tree):\", Score_dt)\n",
    "print(\"Accuracy Score (Logistic Regression):\", Accuracy)\n",
    "print(\"Recall Score (Logistic Regression):\", Recall)\n",
    "print(\"F1 Score (Logistic Regression):\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1399d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (SVM): 0.8010346199761241\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate an SVM classifier\n",
    "Clf_svm = SVC(random_state=0)\n",
    "Clf_svm.fit(X_train, Y_train)\n",
    "Pred_svm = Clf_svm.predict(X_test)\n",
    "Score_svm = metrics.accuracy_score(Y_test, Pred_svm)\n",
    "print(\"Accuracy Score (SVM):\", Score_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34ac883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (XGBoost): 0.7680063668921607\n"
     ]
    }
   ],
   "source": [
    "Clf_xgb = xgb.XGBClassifier(random_state=0)\n",
    "Clf_xgb.fit(X_train, Y_train)\n",
    "Pred_xgb = Clf_xgb.predict(X_test)\n",
    "Score_xgb = metrics.accuracy_score(Y_test, Pred_xgb)\n",
    "print(\"Accuracy Score (XGBoost):\", Score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
